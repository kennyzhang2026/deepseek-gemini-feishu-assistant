import streamlit as st
import os
import platform
import sys
from PIL import Image
from clients.gemini_client import GeminiClient
from clients.feishu_client import FeishuClient

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="AI å…¨èƒ½åŠ©æ‰‹", layout="wide", initial_sidebar_state="expanded")

# --- 2. CSS æ ·å¼ (çº¯å‡€ç‰ˆï¼Œå·²å»é™¤æ‰€æœ‰è°ƒè¯•çº¢æ¡) ---
hide_streamlit_style = """
<style>
    header {visibility: hidden !important;}
    [data-testid="stHeader"] {display: none !important;}
    #MainMenu {visibility: hidden !important;}
    footer {display: none !important;}
    a[href*="streamlit"] {display: none !important;}
    div:has(> a[href*="streamlit"]) {display: none !important;}
    div[class*="viewerBadge"] {display: none !important;}
    .stDeployButton {display: none !important;}
    [data-testid="stStatusWidget"] {display: none !important;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# --- 3. ç¯å¢ƒé…ç½® ---
system_name = platform.system()
if system_name == "Windows":
    print(f"ğŸ–¥ï¸ [App] Windows ç¯å¢ƒ: å¼€å¯ä»£ç†")
    os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'
    os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'
else:
    print(f"â˜ï¸ [App] äº‘ç«¯ç¯å¢ƒ: æ¸…é™¤ä»£ç†")
    for key in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']:
        if key in os.environ:
            del os.environ[key]

# --- 4. åˆå§‹åŒ– ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# å¼ºåˆ¶é‡ç½® Client ä»¥åº”ç”¨æ–°æ¨¡å‹
if "gemini_client" not in st.session_state:
    try:
        st.session_state.gemini_client = GeminiClient()
    except Exception as e:
        st.error(f"âš ï¸ AI æœåŠ¡è¿æ¥å¤±è´¥: {e}")

# ================= ä¾§è¾¹æ  =================
with st.sidebar:
    st.title("ğŸ›ï¸ æ§åˆ¶é¢æ¿")
    
    # æ˜ç¡®æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„ç¡¬ç¼–ç ç‰ˆæœ¬å·
    st.info("å½“å‰æ¨¡å‹: Gemini 1.5 Pro-002 (é«˜æ™ºå•†ç‰ˆ)")
    
    st.subheader("1. è§†è§‰åˆ†æ")
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=['png', 'jpg', 'jpeg'])
    
    st.divider()

    st.subheader("2. é£ä¹¦å­˜æ¡£")
    col_save_1, col_save_2 = st.columns(2)
    
    with col_save_1:
        if st.button("ğŸ’¾ å­˜æœ€è¿‘ä¸€è½®"):
            last_user = ""
            last_ai = ""
            if len(st.session_state.messages) >= 2:
                for m in reversed(st.session_state.messages):
                    if m['role'] == 'user' and not last_user: last_user = m['content']
                    if m['role'] == 'assistant' and not last_ai: last_ai = m['content']
                    if last_user and last_ai: break
            
            if last_user and last_ai:
                try:
                    feishu = FeishuClient(st.secrets["FEISHU_APP_ID"], st.secrets["FEISHU_APP_SECRET"], st.secrets["FEISHU_APP_TOKEN"])
                    records = feishu.format_chat_record(last_user, last_ai, "Gemini-1.5-Pro-002")
                    res = feishu.add_record_to_bitable(st.secrets["FEISHU_TABLE_ID"], records)
                    if res["success"]:
                        st.toast("âœ… ä¿å­˜æˆåŠŸ", icon="ğŸ‰")
                    else:
                        st.error(f"ä¿å­˜å¤±è´¥: {res['error']}")
                except Exception as e:
                    st.error(f"ç³»ç»Ÿé”™è¯¯: {e}")
            else:
                st.warning("æ— å†…å®¹")

    with col_save_2:
        if st.button("ğŸ“š å­˜å…¨éƒ¨å†å²"):
            msgs = st.session_state.messages
            if not msgs:
                st.warning("æ— è®°å½•")
            else:
                try:
                    feishu = FeishuClient(st.secrets["FEISHU_APP_ID"], st.secrets["FEISHU_APP_SECRET"], st.secrets["FEISHU_APP_TOKEN"])
                    progress_bar = st.progress(0)
                    total_pairs = len(msgs) // 2
                    i = 0
                    saved_count = 0
                    while i < len(msgs) - 1:
                        if msgs[i]['role'] == 'user' and msgs[i+1]['role'] == 'assistant':
                            records = feishu.format_chat_record(msgs[i]['content'], msgs[i+1]['content'], "Gemini-1.5-Pro-002[History]")
                            feishu.add_record_to_bitable(st.secrets["FEISHU_TABLE_ID"], records)
                            saved_count += 1
                            if total_pairs > 0: progress_bar.progress(min(saved_count / total_pairs, 1.0))
                            i += 2 
                        else:
                            i += 1
                    progress_bar.empty()
                    st.toast(f"âœ… å·²ä¿å­˜ {saved_count} æ¡", icon="ğŸ‰")
                except Exception as e:
                    st.error(f"å‡ºé”™: {e}")

    st.divider()
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¹¶é‡ç½®", type="primary"):
        st.session_state.messages = []
        if "gemini_client" in st.session_state:
            del st.session_state.gemini_client
        st.rerun()

# ================= ä¸»ç•Œé¢ =================
st.header("ğŸ¤– AI åŠ©æ‰‹ (Gemini 1.5 Pro-002)")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if "image" in message and message["image"]:
            st.image(message["image"], width=250)
        st.markdown(message["content"])

if prompt := st.chat_input("è¾“å…¥é—®é¢˜ (å·²åˆ‡æ¢è‡³ 1.5 Pro-002)..."):
    if "gemini_client" not in st.session_state:
        st.error("è¯·ç‚¹å‡»å·¦ä¸‹è§’é‡ç½®æŒ‰é’®")
    else:
        user_msg = {"role": "user", "content": prompt}
        if uploaded_file:
            uploaded_file.seek(0)
            img_show = Image.open(uploaded_file)
            user_msg["image"] = img_show
            with st.chat_message("user"):
                st.image(img_show, width=250)
                st.markdown(prompt)
        else:
            with st.chat_message("user"):
                st.markdown(prompt)
        
        st.session_state.messages.append(user_msg)

        with st.chat_message("assistant"):
            msg_box = st.empty()
            msg_box.markdown("Thinking (1.5 Pro-002)...")
            try:
                if uploaded_file:
                    response = st.session_state.gemini_client.analyze_image(uploaded_file, prompt)
                else:
                    text_history = [m for m in st.session_state.messages if "image" not in m][:-1]
                    response = st.session_state.gemini_client.generate_content(prompt, chat_history=text_history)
                
                msg_box.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
            except Exception as e:
                msg_box.error(f"Error: {e}")

