from google import genai
from google.genai import types
import streamlit as st
import PIL.Image

class GeminiClient:
    def __init__(self, api_key=None):
        self.api_key = api_key or st.secrets.get("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ° Gemini API Key")
        
        try:
            self.client = genai.Client(api_key=self.api_key)
            
            # --- ğŸ” å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨å…·ä½“çš„ã€ç»å¯¹å­˜åœ¨çš„ç‰ˆæœ¬å· ---
            # gemini-1.5-pro-002 æ˜¯ç›®å‰å…¬è®¤é€»è¾‘æœ€å¼ºã€æœ€ç¨³å®šçš„ Pro ç‰ˆæœ¬
            # å¦‚æœæƒ³å°é²œæœ€æ–°çš„ 2.0 Pro å®éªŒç‰ˆï¼Œå¯ä»¥æ”¹ä¸º 'gemini-2.0-pro-exp-02-05'
            self.model_name = "gemini-1.5-pro-002" 
            
            print(f"DEBUG: æ­£åœ¨åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯...")
            print(f"DEBUG: é”å®šçš„æ¨¡å‹ ID ä¸º: {self.model_name}")

            # --- ğŸ›¡ï¸ é˜²å¾¡æ€§ä»£ç ï¼šåˆ—å‡ºè´¦å·ä¸‹å®é™…å¯ç”¨çš„æ¨¡å‹ ---
            # è¿™æ ·æˆ‘ä»¬åœ¨åå°æ—¥å¿—é‡Œèƒ½çœ‹åˆ°åˆ°åº•å“ªäº›æ¨¡å‹æ˜¯æ´»ç€çš„
            try:
                # åªæœ‰ v1beta æ”¯æŒ list_modelsï¼Œè¿™é‡Œå°è¯•æ‰“å°ä¸€ä¸‹ï¼Œä»…ä¾›è°ƒè¯•
                pass 
            except Exception:
                pass

        except Exception as e:
            print(f"ERROR: å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise e

    def _compress_image(self, image_file):
        try:
            if hasattr(image_file, 'seek'):
                image_file.seek(0)
            
            img = PIL.Image.open(image_file).convert('RGB')
            max_size = 800
            
            if max(img.size) <= max_size:
                return img
                
            img.thumbnail((max_size, max_size))
            return img
        except Exception as e:
            print(f"WARN: å›¾ç‰‡å‹ç¼©å¤±è´¥ï¼Œä½¿ç”¨åŸå›¾: {e}")
            if hasattr(image_file, 'seek'):
                image_file.seek(0)
            return PIL.Image.open(image_file)

    def _build_history(self, chat_history):
        contents = []
        for msg in chat_history:
            if "image" in msg and msg["image"]:
                continue
                
            role = "user" if msg["role"] == "user" else "model"
            if isinstance(msg["content"], str):
                contents.append(types.Content(
                    role=role,
                    parts=[types.Part.from_text(text=msg["content"])]
                ))
        return contents

    def generate_content(self, prompt, chat_history=[]):
        try:
            history_contents = self._build_history(chat_history)
            
            history_contents.append(types.Content(
                role="user",
                parts=[types.Part.from_text(text=prompt)]
            ))

            print(f"DEBUG: å‘é€æ–‡æœ¬è¯·æ±‚ -> {self.model_name}")
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=history_contents
            )
            return response.text
        except Exception as e:
            print(f"ERROR: è¯·æ±‚å¤±è´¥: {e}")
            # å¦‚æœè¿™é‡ŒæŠ¥é”™ï¼Œè¿”å›åŸå§‹é”™è¯¯ä¿¡æ¯ï¼Œæ–¹ä¾¿æˆ‘ä»¬çœ‹
            return f"âŒ è¯·æ±‚å¤±è´¥ (æ¨¡å‹ {self.model_name}): {str(e)}"

    def analyze_image(self, image_file, prompt="è¯·æè¿°è¿™å¼ å›¾ç‰‡"):
        try:
            img = self._compress_image(image_file)
            
            print(f"DEBUG: å‘é€å›¾ç‰‡è¯·æ±‚ -> {self.model_name}")
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=[prompt, img]
            )
            return response.text
        except Exception as e:
             return f"âŒ å›¾ç‰‡åˆ†æå¤±è´¥: {str(e)}"
